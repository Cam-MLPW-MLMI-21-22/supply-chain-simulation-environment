{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import GPy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.model_wrappers import GPyModelWrapper\n",
    "from emukit.model_wrappers.gpy_quadrature_wrappers import BaseGaussianProcessGPy, RBFGPy\n",
    "\n",
    "from emukit.core import ParameterSpace, ContinuousParameter, DiscreteParameter\n",
    "from emukit.core.loop import UserFunctionWrapper\n",
    "\n",
    "from emukit.core import ParameterSpace, ContinuousParameter\n",
    "from emukit.core.initial_designs import RandomDesign\n",
    "\n",
    "from GPy.models import GPRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check that the user function (that provides the data points) returns the appropriate format.\n",
    "\n",
    "Here, User function (that we want to estimate) should return 2d array or a tuple of 2d arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.benchmarks import branin as _branin\n",
    "from emukit.test_functions import branin_function\n",
    "\n",
    "f, _ = branin_function() # or branin()\n",
    "\n",
    "def branin(x, noise_level=0.):\n",
    "    return np.reshape(_branin(x) + noise_level * np.random.randn(), (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scse.api.simulation import run_simulation\n",
    "\n",
    "def f(X):\n",
    "    Y = []\n",
    "    for x in X:\n",
    "        num_batteries = x[0]\n",
    "\n",
    "        cum_reward = run_simulation(time_horizon=336, num_batteries=num_batteries)\n",
    "\n",
    "        Y.append(cum_reward[-1])\n",
    "\n",
    "    Y = np.reshape(np.array(Y), (-1, 1))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial design / data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16],\n",
       "       [ 9],\n",
       "       [13],\n",
       "       [24]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_num_batteries = 25\n",
    "num_batteries = DiscreteParameter('num_batteries', [i for i in range(0, max_num_batteries)])\n",
    "week = 336\n",
    "time_horizon = DiscreteParameter('time_horizon', [i for i in range(0, 52*week, week)])\n",
    "\n",
    "parameter_space = ParameterSpace([num_batteries])\n",
    "design = RandomDesign(parameter_space)\n",
    "\n",
    "num_data_points = 4\n",
    "X = design.get_samples(num_data_points)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = f(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (100, 1)\n",
    "X0 = np.random.randint(-5, 10, shape)\n",
    "X1 = np.random.randint(0, 15, shape)\n",
    "X = np.concatenate((X0, X1), axis=1)\n",
    "Y = np.reshape(np.append([], [branin(x) for x in X]), (-1, 1))\n",
    "\n",
    "# or use RandomDesign\n",
    "parameter_space = ParameterSpace([ContinuousParameter(\n",
    "    'x1', -5, 10), ContinuousParameter('x2', 0, 15)])\n",
    "design = RandomDesign(parameter_space)\n",
    "\n",
    "# if not X:\n",
    "if len(X) != 0: \n",
    "    num_data_points = shape[0]\n",
    "    X = design.get_samples(num_data_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting initial design values (branin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "x_ax, y_ax = np.meshgrid(X0, X1)\n",
    "vals = np.c_[x_ax.ravel(), y_ax.ravel()]\n",
    "fx = np.reshape([branin(val) for val in vals], (shape[0], shape[0]))\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "cm = ax.pcolormesh(x_ax, y_ax, fx,\n",
    "                   norm=LogNorm(vmin=fx.min(),\n",
    "                                vmax=fx.max()),\n",
    "                   cmap='viridis_r')\n",
    "\n",
    "minima = np.array([[-np.pi, 12.275], [+np.pi, 2.275], [9.42478, 2.475]])\n",
    "found_minima = np.reshape([x_ax[np.where(fx == np.min(fx))][0], y_ax[np.where(fx == np.min(fx))][0]], (1, 2))\n",
    "\n",
    "\n",
    "ax.plot(minima[:, 0], minima[:, 1], \"r.\", markersize=14,\n",
    "        lw=0, label=\"Branin Minima\")\n",
    "ax.plot(found_minima[:, 0], found_minima[:, 1], \"y.\", markersize=14,\n",
    "        lw=0, label=\"Sampled Minima\")\n",
    "\n",
    "cb = fig.colorbar(cm)\n",
    "cb.set_label(\"f(x)\")\n",
    "\n",
    "ax.legend(loc=\"best\", numpoints=1)\n",
    "\n",
    "ax.set_xlabel(\"X1\")\n",
    "ax.set_xlim([-5, 10])\n",
    "ax.set_ylabel(\"X2\")\n",
    "ax.set_ylim([0, 15])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Emulator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(1, lengthscale=1e1, variance=1e4)\n",
    "gpy_model = GPy.models.GPRegression(X, Y, kernel, noise_var=1e-10)\n",
    "gpy_model.optimize()\n",
    "\n",
    "\n",
    "model_emukit = GPyModelWrapper(gpy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision loops \n",
    "from emukit.experimental_design import ExperimentalDesignLoop\n",
    "from emukit.bayesian_optimization.loops import BayesianOptimizationLoop\n",
    "from emukit.quadrature.loop import VanillaBayesianQuadratureLoop\n",
    "\n",
    "# Acquisition functions \n",
    "from emukit.bayesian_optimization.acquisitions import ExpectedImprovement\n",
    "from emukit.experimental_design.acquisitions import ModelVariance\n",
    "# from emukit.quadrature.acquisitions import IntegralVarianceReduction\n",
    "from emukit.experimental_design.acquisitions import IntegratedVarianceReduction\n",
    "\n",
    "# Acquistion optimizers\n",
    "from emukit.core.optimization import GradientAcquisitionOptimizer\n",
    "\n",
    "# Stopping conditions\n",
    "from emukit.core.loop import FixedIterationsStoppingCondition\n",
    "from emukit.core.loop import ConvergenceStoppingCondition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.bayesian_optimization.acquisitions.log_acquisition import LogAcquisition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load core elements for Bayesian optimization\n",
    "expected_improvement = ExpectedImprovement(model=model_emukit)\n",
    "us_acquisition = ModelVariance(model_emukit)\n",
    "ivr_acquisition = IntegratedVarianceReduction(model_emukit, parameter_space)\n",
    "\n",
    "\n",
    "log_acq = LogAcquisition(expected_improvement)\n",
    "optimizer = GradientAcquisitionOptimizer(space=parameter_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bayesian optimization object\n",
    "bayesopt_loop = BayesianOptimizationLoop(model=model_emukit,\n",
    "                                         space=parameter_space,\n",
    "                                         acquisition=log_acq,\n",
    "                                         batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the loop and extract the optimum\n",
    "# Run the loop until we either complete 10 steps or converge\n",
    "stopping_condition = FixedIterationsStoppingCondition(\n",
    "    i_max=10) | ConvergenceStoppingCondition(eps=0.01)\n",
    "\n",
    "bayesopt_loop.run_loop(f, stopping_condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_design_samples = num_data_points\n",
    "new_Y = bayesopt_loop.loop_state.Y[initial_design_samples:, :]\n",
    "new_X = bayesopt_loop.loop_state.X[initial_design_samples:, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this \"sorting\" of inputs only works in 1D due to flattening. \n",
    "When we move to 2D, we should not plot lines but scatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = bayesopt_loop.loop_state.X\n",
    "order = new_X.argsort(axis=0)\n",
    "new_X = new_X[order]\n",
    "new_X = new_X.flatten().reshape(-1, 1)\n",
    "new_Y = bayesopt_loop.loop_state.Y[order]\n",
    "new_Y = new_Y.flatten().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_X, new_Y)\n",
    "plt.style.use('seaborn')\n",
    "plt.title(\"Initial runs\")\n",
    "plt.xlabel(parameter_space.parameters[0].name)\n",
    "plt.ylabel(\"Cumulative reward\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.reshape(np.array([i for i in range(0, 25)]), (-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_plot, var_plot = model_emukit.predict(x_plot)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "LEGEND_SIZE = 15\n",
    "plt.plot(new_X, new_Y, \"ro\", markersize=10, label=\"All observations\")\n",
    "plt.plot(X, Y, \"bo\", markersize=10, label=\"Initial observations\")\n",
    "# plt.plot(x_plot, y_plot, \"k\", label=\"Objective Function\")\n",
    "plt.plot(x_plot, mu_plot, \"C0\", label=\"Model\")\n",
    "plt.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - np.sqrt(var_plot)[:, 0], color=\"C0\", alpha=0.6)\n",
    "plt.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + 2 * np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - 2 * np.sqrt(var_plot)[:, 0], color=\"C0\", alpha=0.4)\n",
    "plt.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + 3 * np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - 3 * np.sqrt(var_plot)[:, 0], color=\"C0\", alpha=0.2)\n",
    "\n",
    "plt.legend(loc=2, prop={'size': LEGEND_SIZE})\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$f(x)$\")\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_plot, var_plot = model_emukit.predict(x_plot)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "LEGEND_SIZE = 15\n",
    "plt.plot(new_X, new_Y, \"ro\", markersize=10, label=\"All observations\")\n",
    "plt.plot(X, Y, \"bo\", markersize=10, label=\"Initial observations\")\n",
    "# plt.plot(x_plot, y_plot, \"k\", label=\"Objective Function\")\n",
    "plt.plot(x_plot, mu_plot, \"C0\", label=\"Model\")\n",
    "plt.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - np.sqrt(var_plot)[:, 0], color=\"C0\", alpha=0.6)\n",
    "plt.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + 2 * np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - 2 * np.sqrt(var_plot)[:, 0], color=\"C0\", alpha=0.4)\n",
    "plt.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + 3 * np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - 3 * np.sqrt(var_plot)[:, 0], color=\"C0\", alpha=0.2)\n",
    "\n",
    "plt.legend(loc=2, prop={'size': LEGEND_SIZE})\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$f(x)$\")\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bayesopt_loop.get_results()\n",
    "\n",
    "print(\"minimum reward = {}\".format(results.minimum_value))\n",
    "print(\"(X = {}, Y = {})\".format(results.minimum_location, results.minimum_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_plot = us_acquisition.evaluate(x_plot)\n",
    "ivr_plot = ivr_acquisition.evaluate(x_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IVR is arguably te more principled approach, but often US is preferred over IVR simply because it lends itself to gradient based optimization more easily, is cheaper to compute, and is exact. For both of them (stochastic) gradient base optimizers are used to retrieve the next datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x_plot, us_plot / np.max(us_plot), \"green\", label=\"US\")\n",
    "plt.plot(x_plot, ivr_plot / np.max(ivr_plot) , \"purple\", label=\"IVR\")\n",
    "\n",
    "plt.legend(loc=1, prop={'size': LEGEND_SIZE})\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$f(x)$\")\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving code for later plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress(loop, loop_state):\n",
    "    plt.figure(figsize=FIG_SIZE)\n",
    "    plt.contourf(x_1, x_2, y_reshape)\n",
    "    # plt.plot(x_0_constraint, x_1_constraint, linewidth=3, color='k')\n",
    "    plt.plot(loop_state.X[:-1, 0], loop_state.X[:-1, 1],\n",
    "             linestyle='', marker='.', markersize=16, color='b')\n",
    "    plt.plot(loop_state.X[-1, 0], loop_state.X[-1, 1],\n",
    "             linestyle='', marker='.', markersize=16, color='r')\n",
    "    plt.legend(['Constraint boundary', 'Previously evaluated points', 'Last evaluation'])\n",
    "\n",
    "\n",
    "# Make BO loop\n",
    "bo_loop = BayesianOptimizationLoop(\n",
    "    space, emukit_model, ei, acquisition_optimizer=acquisition_optimizer)\n",
    "# append plot_progress function to iteration end event\n",
    "bo_loop.iteration_end_event.append(plot_progress)\n",
    "bo_loop.run_loop(f, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting 2D branin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "zline = bayesopt_loop.loop_state.Y.flatten()\n",
    "xline = bayesopt_loop.loop_state.X[:, 0]\n",
    "yline = bayesopt_loop.loop_state.X[:, 1]\n",
    "ax.plot_trisurf(xline, yline, zline, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ax, y_ax = np.meshgrid(new_X[:, 0], new_X[:, 1])\n",
    "vals = np.c_[x_ax.ravel(), y_ax.ravel()]\n",
    "fx = np.reshape([branin(val) for val in vals], x_ax.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "cm = ax.pcolormesh(x_ax, y_ax, fx,\n",
    "                   norm=LogNorm(vmin=fx.min(),\n",
    "                                vmax=fx.max()),\n",
    "                   cmap='viridis_r')\n",
    "\n",
    "minima = np.array([[-np.pi, 12.275], [+np.pi, 2.275], [9.42478, 2.475]])\n",
    "\n",
    "found_minima = new_X[np.where((new_Y == np.min(new_Y)))[0]]\n",
    "\n",
    "\n",
    "ax.plot(minima[:, 0], minima[:, 1], \"r.\", markersize=14,\n",
    "        lw=0, label=\"Branin Minima\")\n",
    "ax.plot(found_minima[:, 0], found_minima[:, 1], \"y.\", markersize=14,\n",
    "        lw=0, label=\"Sampled Minima\")\n",
    "\n",
    "cb = fig.colorbar(cm)\n",
    "cb.set_label(\"f(x)\")\n",
    "\n",
    "ax.legend(loc=\"best\", numpoints=1)\n",
    "\n",
    "ax.set_xlabel(\"X1\")\n",
    "ax.set_xlim([-5, 10])\n",
    "ax.set_ylabel(\"X2\")\n",
    "ax.set_ylim([0, 15])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e7fa7328eade0d734d2145bc41f686310ac84f910f69ec4d3e3a3661d80fa54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
